{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Generative Adversarial Network (DCGAN) - PyTorch\n",
    "This notebook contains the same implementation of a Convolutional Generative Adversarial Network (DCGAN) as the python files. The notebook is primarily meant to give a better understanding of the model without the pain to search through the python files. In addition to that code for a run in collaboratory is provided.\n",
    "\n",
    "GANs were first [introduced](https://arxiv.org/abs/1406.2661) in 2014 from Ian Goodfellow and others. A [DCGAN](https://arxiv.org/abs/1511.06434) is an adaption of the normal GAN in which all linear layers are replaced with convolutional layers for better performance. GANs consists of two networks: a generator ***G*** and a discriminator ***D***. The generator is designed to generate realistic looking data \"fake data\" and the discriminator is designed to distinguish between generated \"fake data\" and real data from a dataset. Both networks play a game against each other where the generator tries to fool the discriminator by generating data as real as possible and the discriminator tries to classify fake and real data correctly. \n",
    "\n",
    "The generator is a convolutional network which takes a random vector as input and outputs another vector which can be reshaped to an image\n",
    "The discriminator is a convolutional classifier that takes an image vector as input and outputs a probability of that image being real.\n",
    "This game leads to a generator producing data that is indistinguishable from real data to the discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Collaboratory Code\n",
    "Uncommend the following cells if you're running this notebook in google collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----MOUNT DRIVE-----\n",
    "#from google.colab import drive\n",
    "#drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----INSTALL PYTORCH-----\n",
    "#from os.path import exists\n",
    "#from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "#cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "#accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----REINSTALL PILLOW ON COLLAB-----\n",
    "#!pip install Pillow==4.0.0\n",
    "#!pip install PIL\n",
    "#!pip install image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import PyTorch dependencies\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories for images and svhn dataset\n",
    "os.makedirs('svhn_data', exist_ok=True)\n",
    "os.makedirs('generated_images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Transform Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [SVHN](http://ufldl.stanford.edu/housenumbers/) dataset will be used as an example dataset if nothing else is specified. For a custom dataset, change the custom_image_path parameter. JPEG images are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: svhn_data/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "#-----DATASET PARAMETERS-----\n",
    "custom_image_path = None\n",
    "batch_size = 128\n",
    "# Don't change this parameter unless you are using a different kernel\n",
    "# No linear layers are used so the dimensions after the last convolition need to be 1*1*1\n",
    "image_size = 65\n",
    "#---------------------------\n",
    "\n",
    "# Resize data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "if custom_image_path != None:\n",
    "    train_dataset = datasets.ImageFolder(custom_image_path)\n",
    "else:\n",
    "    train_dataset = datasets.SVHN(root=\"svhn_data\", split=\"train\", download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_convert(tensor, rescale=False):\n",
    "    # Clone image and transfer it to CPU\n",
    "    image = tensor.cpu().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    # Switch dimensions form (3, 200, 200) to (200, 200, 3)\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    if rescale:\n",
    "        # Rescale image from tanh output (1, -1) to rgb (0, 255)\n",
    "        image = ((image + 1) * 255 / (2)).astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "# Show one image \n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "image = im_convert(images[0])\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale image values from -1 to 1 to be close to the output of the tanh function\n",
    "def scale(x, feature_range=(-1, 1)):\n",
    "    min, max = feature_range\n",
    "    x = x * (max-min) + min\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create convolutional layers with batch normalization and without bias terms\n",
    "def conv(in_channels, out_channels, kernel_size, stride=1, padding=0, batch_norm=True):\n",
    "    layers = []\n",
    "    if batch_norm:\n",
    "        # If batch_norm is true add a batch norm layer\n",
    "        conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        layers = [conv_layer, batch_norm]\n",
    "    else:\n",
    "        # If batch_norm is false just add a conv layer\n",
    "        conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        layers.append(conv_layer)\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, conv_dim=32):\n",
    "        super().__init__()\n",
    "        # Define hidden convolutional layers\n",
    "        self.input = conv(3, conv_dim, kernel_size=5, stride=2, padding=2, batch_norm=False)\n",
    "        self.conv1 = conv(conv_dim, conv_dim*2, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = conv(conv_dim*2, conv_dim*4, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv3 = conv(conv_dim*4, conv_dim*8, kernel_size=5, stride=2, padding=2)\n",
    "        self.output = conv(conv_dim*8, 1, kernel_size=5, stride=1, padding=0, batch_norm=False)\n",
    "        # Activation function\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.02)\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.input(x))\n",
    "        x = self.leaky_relu(self.conv1(x))\n",
    "        x = self.leaky_relu(self.conv2(x))\n",
    "        x = self.leaky_relu(self.conv3(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create transpose convolutional layers with batch normalization and without bias terms\n",
    "def conv_trans(in_channels, out_channels, kernel_size, stride=1, padding=0, batch_norm=True):\n",
    "    layers = []\n",
    "    if batch_norm:\n",
    "        # If batch_norm is true add a batch norm layer\n",
    "        conv_layer = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        layers = [conv_layer, batch_norm]\n",
    "    else:\n",
    "        # If batch_norm is false just add a transpose conv layer\n",
    "        conv_layer = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        layers.append(conv_layer)\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, conv_dim=32, z_dim=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define hidden transpose convolutional layers\n",
    "        self.input = conv_trans(z_dim, conv_dim*8, kernel_size=5, stride=1, padding=0)\n",
    "        self.conv_trans1 = conv_trans(conv_dim*8, conv_dim*4, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv_trans2 = conv_trans(conv_dim*4, conv_dim*2, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv_trans3 = conv_trans(conv_dim*2, conv_dim, kernel_size=5, stride=2, padding=2)\n",
    "        self.output = conv_trans(conv_dim, 3, kernel_size=5, stride=2, padding=2, batch_norm=False)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.conv_trans1(x))\n",
    "        x = F.relu(self.conv_trans2(x))\n",
    "        x = F.relu(self.conv_trans3(x))\n",
    "        x = torch.tanh(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Network\n",
    "z_dim = 100\n",
    "conv_dim = 32\n",
    "\n",
    "D = Discriminator(conv_dim=conv_dim)\n",
    "G = Generator(conv_dim=conv_dim, z_dim=z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a gpu is available move all models to gpu\n",
    "if torch.cuda.is_available():\n",
    "    G = G.cuda()\n",
    "    D = D.cuda()\n",
    "    print(\"GPU available. Moved models to GPU.\")\n",
    "else:\n",
    "    print(\"Training on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_loss(predictions, smooth=False):\n",
    "    batch_size = predictions.shape[0]\n",
    "    labels = torch.ones(batch_size)\n",
    "    # Smooth labels for discriminator to weaken learning\n",
    "    if smooth:\n",
    "        labels = labels * 0.9\n",
    "    # We use the binary cross entropy loss | Model has a sigmoid function\n",
    "    criterion = nn.BCELoss()\n",
    "    # Move models to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        labels = labels.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    loss = criterion(predictions.squeeze(), labels)\n",
    "    return loss\n",
    "\n",
    "def fake_loss(predictions):\n",
    "    batch_size = predictions.shape[0]\n",
    "    labels = torch.zeros(batch_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    # Move models to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        labels = labels.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    loss = criterion(predictions.squeeze(), labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_vector(batch_size, length):\n",
    "    # Sample from a Gaussian distribution\n",
    "    z_vec = torch.randn(batch_size, length, 1, 1).float()\n",
    "    if torch.cuda.is_available():\n",
    "        z_vec = z_vec.cuda()\n",
    "    return z_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----TRAINING PARAMETERS-----\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "#-----------------------------\n",
    "\n",
    "# Adam optimizer as trainigs function\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=[beta1, beta2])\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=[beta1, beta2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(generator, discriminator, optimizer, real_data, batch_size, z_size):\n",
    "    # Set discriminator into training mode and reset gradients\n",
    "    discriminator.train()\n",
    "    optimizer.zero_grad()\n",
    "    # Rescale images into -1 to 1 range\n",
    "    real_data = scale(real_data)\n",
    "    # Train on real data\n",
    "    real_data_logits = discriminator.forward(real_data)\n",
    "    loss_real = real_loss(real_data_logits, smooth=True)\n",
    "    # Train on fake data\n",
    "    z_vec = random_vector(batch_size, z_size)\n",
    "    fake_data = generator.forward(z_vec)\n",
    "    fake_data_logits = discriminator.forward(fake_data)\n",
    "    loss_fake = fake_loss(fake_data_logits)\n",
    "    # Calculate total loss, gradients and take optimization step\n",
    "    total_loss = loss_fake + loss_real\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(generator, discriminator, optimizer, batch_size, z_size):\n",
    "    # Reset gradients and set model to training mode\n",
    "    generator.train()\n",
    "    optimizer.zero_grad()\n",
    "    # Generate fake data\n",
    "    z_vec = random_vector(batch_size, z_size)\n",
    "    fake_data = generator.forward(z_vec)\n",
    "    # Train generator with output of discriminator\n",
    "    discriminator_logits = discriminator.forward(fake_data)\n",
    "    # Reverse labels\n",
    "    loss = real_loss(discriminator_logits)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainigs loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# After how many batches should generated sample images be shown?\n",
    "print_every = 200\n",
    "# How many images should be shown?\n",
    "sample_size = 8\n",
    "# After how many epochs should the loss be plotted?\n",
    "plot_every = 5\n",
    "# Create some sample noise\n",
    "sample_noise = random_vector(sample_size, z_dim)\n",
    "#-------------------------\n",
    "\n",
    "# Keep track of losses\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    for batch_i, (images, _) in enumerate(train_loader):\n",
    "        batch_size = images.shape[0]\n",
    "        # Move images to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "        # Train discriminator\n",
    "        d_loss = train_discriminator(G, D, d_optimizer, images, batch_size, z_dim)\n",
    "        # Train generator\n",
    "        g_loss = train_generator(G, D, g_optimizer, batch_size, z_dim)\n",
    "        \n",
    "        # Keep track of losses\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_loss)\n",
    "        \n",
    "        # Print some sample pictures\n",
    "        if (batch_i % print_every == 0):\n",
    "            print(\"Epoch: {}, Batch: {}, D-Loss: {}, G-Loss: {}\".format(e, batch_i, d_loss, g_loss))\n",
    "            # Make sample generation\n",
    "            G.eval()\n",
    "            fig, axes = plt.subplots(1, sample_size, figsize=(20, 10))\n",
    "            # Generate predictions\n",
    "            predictions = G.forward(sample_noise)\n",
    "            for i in range(sample_size):\n",
    "                axes[i].imshow(im_convert(predictions[i], rescale=True))\n",
    "            plt.show()\n",
    "    if (e % plot_every == 0):\n",
    "        # Print losses\n",
    "        plt.plot(d_losses, label=\"Discriminator\", alpha=0.5)\n",
    "        plt.plot(g_losses, label=\"Generator\", alpha=0.5)\n",
    "        plt.title(\"Trainings loss\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses, label=\"Discriminator\", alpha=0.5)\n",
    "plt.plot(g_losses, label=\"Generator\", alpha=0.5)\n",
    "plt.title(\"Trainings loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(num_samples):\n",
    "    G.eval()\n",
    "    z_vec = random_vector(num_samples, z_dim)\n",
    "    predictions = G.forward(z_vec)\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(20, 10))\n",
    "    for i in range(num_samples):\n",
    "        axes[i].imshow(im_convert(predictions[i], rescale=True), cmap=\"gray\")              \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
